{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22f73bf-b954-4026-a926-b88aeff599e4",
   "metadata": {},
   "source": [
    "# Random Forests Algoritması\n",
    "\n",
    "### Random Forest Regresyon, birçok karar ağacının bir araya gelerek oluşturduğu bir ensemble (kombinasyon) yöntemidir. Ensemble yöntemleri, birden fazla öğrenme modelinin birleştirilerek daha güçlü ve daha istikrarlı bir model oluşturulmasını sağlar.\n",
    "\n",
    "## Random Forest Regresyon'un temel çalışma prensibi şu şekildedir:\n",
    "\n",
    "### Veri kümesi rastgele örneklemlerle alt kümeler (bootstrap örnekleme) olarak seçilir. Bu, veri kümesindeki gözlemlerden rastgele seçimler yaparak farklı alt kümeler oluşturulmasını sağlar. \n",
    "\n",
    "### Her alt küme için bir karar ağacı oluşturulur. Karar ağacı, veri seti üzerinde bir dizi test sorusu sorarak veriyi bölen ve sonunda tahmin yapabilen bir ağaç yapısıdır.\n",
    "\n",
    "### Karar ağaçlarının oluşturulmasında, her düğümde veri setinin bir alt kümesi rastgele seçilen özellikler üzerinde test edilir. Bu özellikler rastgele bir şekilde seçilir ve en iyi bölünme noktası seçilir.\n",
    "\n",
    "### Karar ağaçları, yaprak düğümlerinde tahmin yapmak için kullanılan sayısal bir değerle sonlanır. Bu değer, yaprak düğümüne dahil olan veri noktalarının hedef değişkeninin ortalamasıdır.\n",
    "\n",
    "### Tahmin yaparken, tüm karar ağaçlarının tahminleri alınır ve genellikle bu tahminlerin ortalaması kullanılarak final tahmin değeri elde edilir.\n",
    "\n",
    "\n",
    "## Random Forest Regresyon'un sağladığı birçok avantaj vardır:\n",
    "\n",
    "### Robustluk: Birden fazla karar ağacının birleştirilmesi, tek bir karar ağacının hatalarının ortadan kalkmasını sağlar. Bu, modelin daha dengeli ve güvenilir tahminler yapmasını sağlar.\n",
    "\n",
    "### Özellik Seçimi: Karar ağaçlarının oluşturulmasında rastgele özelliklerin seçilmesi, modelin genellemesini ve aşırı uyumunu (overfitting) azaltır. Bu, veri bilimcisinin tüm özellikleri dikkate almadan önemli olanları belirlemesini sağlar.\n",
    "\n",
    "### Eksik Veri Yönetimi: Random Forest Regresyon, eksik veriye sahip veri kümeleriyle iyi başa çıkabilir. Eksik veriye sahip özelliklerin kullanılmasıyla, tahmin yapma yeteneği korunur.\n",
    "\n",
    "### Outlier (aykırı değer) Toleransı: Random Forest Regresyon, tek bir ağaçtan daha fazla karar ağacı kullanarak daha iyi bir aykırı değer toleransı sağlar. Bu, modelin dışsal gürültüye daha dirençli olmasını sağlar.\n",
    "\n",
    "\n",
    "## Random Forest Regresyon'u kullanırken dikkate almamız gereken bazı detaylar vardır:\n",
    "\n",
    "### Karar ağaçlarının sayısı: Random Forest Regresyon'da kullanılacak karar ağacı sayısı, bir hiperparametre olarak belirlenir. Daha fazla ağaç, daha iyi bir genelleme sağlayabilir, ancak daha yüksek hesaplama maliyeti gerektirir.\n",
    "\n",
    "### Hiperparametre ayarlaması: Random Forest Regresyon'un performansını optimize etmek için hiperparametrelerin ayarlanması önemlidir. Karar ağacı sayısı, derinlik, bölünme kriterleri gibi parametrelerin seçimi, modelin performansını etkileyebilir.\n",
    "\n",
    "### Özellik Önemi: RandomForest Regresyon, özelliklerin ölçeğine karşı dirençli olmasına rağmen, bazı durumlarda veri ölçeklendirme işlemi gerekebilir. Özelliklerin aynı ölçekte olması, modelin daha iyi performans göstermesini sağlayabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c78369-670c-4a86-91cf-0d306370ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d95c8d4-2671-43d9-a436-b1cb4b72ed34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437c33d-0d09-4713-b875-7c47513466cc",
   "metadata": {},
   "source": [
    "# Parametreler Hakkında\n",
    "\n",
    "### n_estimators:\n",
    "#### İşlevi: Oluşturulacak karar ağacı sayısını belirler.\n",
    "#### Varsayılan değer: 100\n",
    "#### Genellikle daha yüksek bir değer, daha iyi bir genelleme performansı sağlayabilir, ancak hesaplama maliyeti artar.\n",
    "\n",
    "\n",
    "### criterion:\n",
    "#### İşlevi: Bölünme kalitesini ölçmek için kullanılan kriteri belirler.\n",
    "#### Varsayılan değer: 'mse' (ortalama karesel hata)\n",
    "#### Diğer seçenekler: 'mae' (ortalama mutlak hata)\n",
    "#### 'mse' genellikle regresyon problemleri için daha yaygın kullanılır.\n",
    "\n",
    "\n",
    "### max_depth:\n",
    "#### İşlevi: Karar ağaçlarının maksimum derinliğini belirler.\n",
    "#### Varsayılan Değer: None (Derinlik sınırlaması yok)\n",
    "#### Derinliği sınırlamak, modelin aşırı uyuma (overfitting) eğilimini azaltabilir.\n",
    "\n",
    "\n",
    "### min_samples_split:\n",
    "#### İşlevi: Bir iç düğümün bölünmesi için gereken minimum örnek sayısını belirler.\n",
    "#### Varsayılan değer: 2\n",
    "#### Daha yüksek bir değer, modelin daha genel kararlar vermesini sağlayabilir.\n",
    "\n",
    "\n",
    "### min_samples_leaf:\n",
    "#### İşlevi: Bir yaprak düğümünün oluşması için gereken minimum örnek sayısını belirler.\n",
    "#### Varsayılan değer: 1\n",
    "#### Daha yüksek bir değer, modelin daha basit bir yapıya sahip olmasını sağlayabilir.\n",
    "\n",
    "\n",
    "### max_features:\n",
    "#### İşlevi: Her ağaçta kullanılacak maksimum özellik sayısını belirler.\n",
    "#### Varsayılan değer: auto (sqrt(n_features))\n",
    "#### Diğer seçenekler: 'sqrt', 'log2', None veya sayısal değerler\n",
    "#### Özellik seçiminin rastgelelik derecesini kontrol eder.\n",
    "\n",
    "\n",
    "### random_state:\n",
    "#### İşlevi: Tekrarlanabilir sonuçlar elde etmek için kullanılan bir tohum değeridir.\n",
    "#### Varsayılan değer: None\n",
    "#### Belirli bir değer atanması, her çalıştırmada aynı sonuçları elde etmemizi sağlar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
